{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "adS1tb0wFA21"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0pDuFt5B2_41"
      },
      "outputs": [],
      "source": [
        "class targetset(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy') > 0.95 and logs.get('val_accuracy') > 0.90):\n",
        "            print(\"\\nreached\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YBUwOL77GufO"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/MyDrive/capstone_needs/DATASET/clean_datav4.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/clean_datav4')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrkChwnuHFWn",
        "outputId": "7993a2eb-02c7-4602-8b51-c28ca64511a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18849 images belonging to 4 classes.\n",
            "Found 4711 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = '/content/clean_datav4'\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   shear_range=0.2,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   validation_split=0.2,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUPV9pWIJU5J"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    # Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3), kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    # MaxPooling2D(2, 2),\n",
        "    # Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    # MaxPooling2D(2, 2),\n",
        "    # Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    # MaxPooling2D(2, 2),\n",
        "    # Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    # MaxPooling2D(2, 2),\n",
        "    # Flatten(),\n",
        "    # Dropout(0.5),\n",
        "    # Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
        "    # Dense(train_generator.num_classes, activation='softmax')\n",
        "    tf.keras.Input((224,224,3)),\n",
        "    tf.keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "callback = targetset()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "batch_size = 32\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples // batch_size,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples // batch_size,\n",
        "      verbose=2, callbacks=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "490SJaumMXiC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laGlEUY4NdFE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    path = '/content/' + filename\n",
        "    img = load_img(path, target_size=(224, 224))\n",
        "    x = img_to_array(img) / 255\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=32)\n",
        "\n",
        "    print(classes[0])  # printing the probabilities\n",
        "\n",
        "    # Find the index of the highest probability\n",
        "    max_index = np.argmax(classes[0])\n",
        "\n",
        "    # Define your class names in order\n",
        "    class_names = [\"b3\", \"organic\", \"recyclable\", \"residue\"]\n",
        "\n",
        "    # Check if the highest probability is above a threshold, say 0.5\n",
        "    if classes[0][max_index] > 0.5:\n",
        "        print(f\"{filename} is most likely '{class_names[max_index]}' with a probability of {classes[0][max_index]}\")\n",
        "    else:\n",
        "        print(f\"{filename} classification is uncertain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VzsoeHNMRBQ"
      },
      "outputs": [],
      "source": [
        "model.save('model4c.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh00vEgNMoLx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model, model_from_json\n",
        "model_h5 = load_model('/content/model4c.h5')\n",
        "model_json = model_h5.to_json()\n",
        "with open('model4c.json', 'w') as json_file:\n",
        "    json_file.write(model_json)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}